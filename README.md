# üß© Unsupervised Detection of LLM-Generated Text in Korean  
### Using Syntactic and Semantic Cues (TOCSIN + SimLLM + Ensemble)

This repository implements an **unsupervised framework** for detecting Korean texts generated by Large Language Models (LLMs).  
It is based on the paper:  
**"Unsupervised Detection of LLM-Generated Text in Korean Using Syntactic and Semantic Cues" (ARR 2025)**

---

## üîç Overview

As Large Language Models (LLMs) are increasingly used for content creation, distinguishing between **human-written** and **AI-generated** text has become a critical challenge ‚Äî especially in **low-resource languages** such as Korean, where labeled datasets are scarce.  
Most prior studies on AI-text detection have focused on English and rely heavily on **supervised classifiers**, which struggle to generalize across domains, model families, or prompts.

To address these limitations, this repository implements an **unsupervised detection framework** specialized for Korean, built upon the ideas of **syntactic token cohesiveness (TOCSIN)** and **semantic regeneration similarity (SimLLM)**.  
The framework constructs a **pairwise dataset** from human-written Korean texts by prompting an LLM to generate both **continuation-style** and **regeneration-style** variants. These paired samples allow the model to capture two complementary detection signals:

- **TOCSIN** identifies structural irregularities by perturbing tokens and observing how the semantics change, revealing differences in local cohesiveness between human and machine text.  
- **SimLLM** measures semantic stability through regeneration: it rewrites a sentence while preserving meaning, then compares the semantic similarity between the original and regenerated versions.

By integrating both cues through **ensemble fusion** (weighted-sum or sigmoid-based), the framework achieves robust and consistent detection performance across diverse domains (news, essays, abstracts) and LLM families (GPT-3.5, GPT-4o, HyperCLOVA X, LLaMA-3-8B).  
Importantly, the system operates **without any labeled data or model training**, making it highly adaptable to multilingual and real-world applications.

---

## üß† Key Features

- **Pairwise Dataset Generation**  
  - Builds `x`, `x_co`, `x_re-h`, and `x_re-g` sets from each human-written sentence using GPT-3.5 Turbo.  
  - Continuation ‚Üí Regeneration ‚Üí Re-regeneration pipeline.

- **Pseudo-Pairing for Single Sentence Inference**  
  - When given only one input text, the system automatically generates comparison sentences (`x_co`, `x_re-h`, `x_re-g`) in real time and performs detection.

- **Model-Agnostic Design**  
  - Scoring backbone can be replaced (e.g., KoBERT, Distil-KoBERT, mBART, BARTpho, WangchanBERTa).  
  - Easily extensible to multilingual detection tasks.


